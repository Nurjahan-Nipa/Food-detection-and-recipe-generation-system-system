{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is a combination of everything needed to run our cook vision on a machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this to install all the requirements if you don't hava them already installed in your venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules needed for various runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "from ultralytics import YOLO\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After downloading the FOOD-101 Data, you should change the DIR as needed to the root DIR of the food data and align all the other DIR as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script for splitting the food dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "raw_images_root = \"/home/classes/ee7722/ee772210/Downloads/food-101/images/\"  # path to original class folders (e.g. apple_pie/*.jpg)\n",
    "output_root = \"datasets/food101_yolo\"\n",
    "train_txt = \"/home/classes/ee7722/ee772210/Downloads/food-101/meta/train.txt\"\n",
    "val_txt = \"/home/classes/ee7722/ee772210/Downloads/food-101/meta/test.txt\"  # Food-101 calls it test.txt\n",
    "\n",
    "# === Output directories ===\n",
    "image_train = os.path.join(output_root, \"images\", \"train\")\n",
    "image_val = os.path.join(output_root, \"images\", \"val\")\n",
    "label_train = os.path.join(output_root, \"labels\", \"train\")\n",
    "label_val = os.path.join(output_root, \"labels\", \"val\")\n",
    "\n",
    "# === Create dirs if they don't exist ===\n",
    "for d in [image_train, image_val, label_train, label_val]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# === Load class names ===\n",
    "with open(\"/home/classes/ee7722/ee772210/Downloads/food-101/meta/classes.txt\") as f:\n",
    "    class_names = [line.strip() for line in f]\n",
    "class_dict = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# === Function to convert image and generate label ===\n",
    "def process_list(txt_file, image_dir, label_dir):\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            rel_path = line.strip()  # e.g., apple_pie/123456\n",
    "            class_name = rel_path.split(\"/\")[0]\n",
    "            img_name = rel_path.split(\"/\")[1] + \".jpg\"\n",
    "            class_id = class_dict[class_name]\n",
    "\n",
    "            src_img_path = os.path.join(raw_images_root, class_name, img_name)\n",
    "            dst_img_path = os.path.join(image_dir, f\"{class_name}_{img_name}\")\n",
    "            dst_lbl_path = os.path.join(label_dir, f\"{class_name}_{img_name.replace('.jpg', '.txt')}\")\n",
    "\n",
    "            if not os.path.exists(src_img_path):\n",
    "                print(f\"Image missing: {src_img_path}\")\n",
    "                continue\n",
    "\n",
    "            shutil.copy2(src_img_path, dst_img_path)\n",
    "\n",
    "            # Create a bounding box that spans most of the image (assume object-centered)\n",
    "            try:\n",
    "                with Image.open(src_img_path) as img:\n",
    "                    w, h = img.size\n",
    "                # YOLO format: <class> <x_center> <y_center> <width> <height> (normalized)\n",
    "                bbox = [class_id, 0.5, 0.5, 0.9, 0.9]\n",
    "                with open(dst_lbl_path, \"w\") as f_lbl:\n",
    "                    f_lbl.write(\" \".join([str(x) for x in bbox]) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed processing {src_img_path}: {e}\")\n",
    "\n",
    "# === Generate train and val splits with labels ===\n",
    "process_list(train_txt, image_train, label_train)\n",
    "process_list(val_txt, image_val, label_val)\n",
    "\n",
    "print(\"‚úÖ Dataset organized and YOLO labels generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data.yaml file for Yolov8 modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Epoch as needed\n",
    "%yolo task=detect      mode=train      model=yolov8n.pt      data=data.yaml      epochs=50      imgsz=640      batch=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating dish to ingredients json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "CLASSES_FILE = \"/home/classes/ee7722/ee772210/Downloads/food-101/meta/classes.txt\"\n",
    "RECIPES_FILE = \"datasets/recipe-ingredients/train.json\"\n",
    "OUTPUT_FILE = \"dish2ingredients.json\"\n",
    "\n",
    "FUZZY_THRESHOLD = 80  # Match quality (0‚Äì100); lower = more aggressive\n",
    "\n",
    "# === STEP 1: Load Food-101 class names ===\n",
    "with open(CLASSES_FILE, \"r\") as f:\n",
    "    food101_dishes = [line.strip() for line in f]\n",
    "\n",
    "# === STEP 2: Load Kaggle recipe dataset ===\n",
    "with open(RECIPES_FILE, \"r\") as f:\n",
    "    recipes = json.load(f)\n",
    "\n",
    "# === STEP 3: Match dishes to recipes by fuzzy keyword matching ===\n",
    "dish_to_ingredients = defaultdict(list)\n",
    "\n",
    "for dish in food101_dishes:\n",
    "    dish_name = dish.replace(\"_\", \" \").lower()\n",
    "\n",
    "    for recipe in recipes:\n",
    "        ingredients = [ing.lower() for ing in recipe[\"ingredients\"]]\n",
    "        combined = \" \".join(ingredients)\n",
    "\n",
    "        # Fuzzy match the dish name to the combined ingredients string\n",
    "        score = fuzz.partial_ratio(dish_name, combined)\n",
    "        if score >= FUZZY_THRESHOLD:\n",
    "            dish_to_ingredients[dish].extend(ingredients)\n",
    "\n",
    "print(f\"‚úÖ Matched recipes for {len(dish_to_ingredients)} out of {len(food101_dishes)} classes.\")\n",
    "\n",
    "# === STEP 4: Count and save top ingredients for each dish ===\n",
    "dish2ingredients_final = {}\n",
    "for dish, all_ingredients in dish_to_ingredients.items():\n",
    "    ingredient_counts = Counter(all_ingredients)\n",
    "    top_ingredients = [ing for ing, _ in ingredient_counts.most_common(10)]\n",
    "    dish2ingredients_final[dish] = top_ingredients\n",
    "\n",
    "# Save to JSON\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    json.dump(dish2ingredients_final, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved dish2ingredients.json to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Streamlit UI to give a better UI Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dish-to-ingredient map\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "\n",
    "with open(\"dish2ingredients.json\") as f:\n",
    "    dish_map = json.load(f)\n",
    "\n",
    "\n",
    "# === Load Mistral-7B-Instruct model locally ===\n",
    "@st.cache_resource\n",
    "def load_mistral_model():\n",
    "    model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, mistral_model = load_mistral_model()\n",
    "\n",
    "\n",
    "# === Step 2: Recipe Generator ===\n",
    "def generate_recipe_steps(dish, ingredients):\n",
    "    prompt = f\"Give me a clear at least 5-step recipe for making {dish} using the following ingredients: {', '.join(ingredients)}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(mistral_model.device)\n",
    "    outputs = mistral_model.generate(**inputs, max_new_tokens=300)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# === Streamlit UI ===\n",
    "st.set_page_config(page_title=\"CookVision\", layout=\"centered\")\n",
    "st.title(\"üç≥ CookVision: AI Cooking Assistant\")\n",
    "st.markdown(\"Upload a food image to detect the dish and get a recipe with likely ingredients.\")\n",
    "\n",
    "upload_dir = \"data/uploads\"\n",
    "os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "uploaded_file = st.file_uploader(\"üì∑ Upload a food image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    with tempfile.NamedTemporaryFile(delete=False, dir=upload_dir, suffix=\".jpg\") as tmp:\n",
    "        tmp.write(uploaded_file.read())\n",
    "        image_path = tmp.name\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    st.image(image, caption=\"üì∏ Uploaded Image\", use_container_width=True)\n",
    "\n",
    "    # === Detection Phase ===\n",
    "    with st.spinner(\"Detecting dish...\"):\n",
    "        results = model(image_path)\n",
    "        detected_dishes = set()\n",
    "\n",
    "        for r in results:\n",
    "            for box in r.boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                class_name = model.names[class_id]\n",
    "                detected_dishes.add(class_name)\n",
    "\n",
    "    if detected_dishes:\n",
    "        for dish in detected_dishes:\n",
    "            st.subheader(f\"üçΩÔ∏è Detected Dish: {dish.capitalize()}\")\n",
    "\n",
    "            # Get ingredients\n",
    "            ingredients = dish_map.get(dish, [\"‚ùì Ingredients not found\"])\n",
    "            st.markdown(\"**üßæ Inferred Ingredients:** \" + \", \".join(ingredients))\n",
    "\n",
    "            # Get recipe steps\n",
    "            with st.spinner(\"üß† Generating recipe...\"):\n",
    "                recipe = generate_recipe_steps(dish, ingredients)\n",
    "\n",
    "            st.markdown(\"**üë©‚Äçüç≥ Suggested Recipe Steps:**\")\n",
    "            st.markdown(recipe)\n",
    "    else:\n",
    "        st.warning(\"‚ö†Ô∏è No recognizable dish detected.\")\n",
    "else:\n",
    "    st.info(\"Upload a food photo to get started!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the Streamlit UI\n",
    "%streamlit runs app_ui2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
